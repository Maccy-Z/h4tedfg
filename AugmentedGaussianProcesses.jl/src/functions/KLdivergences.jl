# function custom_mapreduce(map_fn, reduce_fn, list1, list2, list3)
#     @info "Start custom_mapreduce"
#     println(" ")
#     result = 0. #map_fn(first(collection), a[1], b[1])
#     for (gp, X, k_mat) in zip(list1, list2, list3)  # Skip the first element because it's already in the result
#         Î¼, Î¼â‚€, Î£, K = gp.post.Î¼, gp.prior.Î¼â‚€(X), gp.post.Î£, k_mat.K
#
#         mapped_item = (logdet(K) - logdet(Î£) + tr(K \ Î£) + invquad(K, Î¼ - Î¼â‚€) - length(Î¼)) / 2  # Apply the mapping function
#         result = result + mapped_item  # Combine with the current result using the reduction function
#     end
#     @info "Complete cusom mapreduce"
#     return result
# end


## KL Divergence between the GP Prior and the variational distribution
function GaussianKL(model::AbstractGPModel, state)
    @info "GKL 1"
    #ret_val = custom_mapreduce(GaussianKL, +, model.f, Zviews(model), state.kernel_matrices)
    # ret_val = custom_mapreduce(nothing, nothing, model.f, (model.data.X,model.data.X,model.data.X), state.kernel_matrices)

    ret_val = 0.
    for (gp, X, k_mat) in zip(model.f, (model.data.X,model.data.X,model.data.X), state.kernel_matrices)  # Skip the first element because it's already in the result
        Î¼, Î¼â‚€, Î£, K = gp.post.Î¼, gp.prior.Î¼â‚€(X), gp.post.Î£, k_mat.K

        mapped_item = (logdet(K) - logdet(Î£) + tr(K \ Î£) + invquad(K, Î¼ - Î¼â‚€) - length(Î¼)) / 2  # Apply the mapping function
        ret_val = ret_val + mapped_item  # Combine with the current result using the reduction function
    end
    return ret_val
end

# function GaussianKL(gp::AbstractLatent, X::AbstractVector, k_mat)
#     @info "GKL 2"
#     return GaussianKL(gp.post.Î¼, gp.prior.Î¼â‚€(X), gp.post.Î£, k_mat.K)
# end


# ## See https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions ##
# function GaussianKL(
#     Î¼::AbstractVector,
#     Î¼â‚€::AbstractVector,
#     Î£::Symmetric{T,Matrix{T}},
#     K::Cholesky{T,Matrix{T}},
# ) where {T<:Real}
#     @info "GKL 3"
#     a = (logdet(K) - logdet(Î£) + tr(K \ Î£) + invquad(K, Î¼ - Î¼â‚€) - length(Î¼)) / 2
#     return a
# end

# function GaussianKL(
#     Î¼::AbstractVector{T},
#     Î¼â‚€::AbstractVector,
#     Î£::Symmetric{T,Matrix{T}},
#     K::AbstractMatrix{T},
# ) where {T<:Real}
#     @info "At GaussianKL4"
#
#     K
#     return (logdet(K) - logdet(Î£) + tr(K \ Î£) + dot(Î¼ - Î¼â‚€, K \ (Î¼ - Î¼â‚€)) - length(Î¼)) / 2
# end

extraKL(::AbstractGPModel{T}, ::Any) where {T} = zero(T)

"""
    extraKL(model::OnlineSVGP)

Extra KL term containing the divergence with the GP at time t and t+1
"""
function extraKL(model::OnlineSVGP{T}, state) where {T}
    return mapreduce(
        +, model.f, state.opt_state, state.kernel_matrices
    ) do gp, opt_state, kernel_mat
        prev_gp = opt_state.previous_gp
        Îºâ‚Î¼ = kernel_mat.Îºâ‚ * mean(gp)
        KLâ‚ = prev_gp.prevð“›â‚
        KLâ‚ +=
            -sum(
                trace_ABt.(
                    Ref(prev_gp.invDâ‚),
                    [kernel_mat.KÌƒâ‚, kernel_mat.Îºâ‚ * cov(gp) * transpose(kernel_mat.Îºâ‚)],
                ),
            ) / 2
        KLâ‚ += dot(prev_gp.prevÎ·â‚, Îºâ‚Î¼) - dot(Îºâ‚Î¼, prev_gp.invDâ‚ * Îºâ‚Î¼) / 2
        return KLâ‚
    end
end
#
# InverseGammaKL(Î±, Î², Î±â‚š, Î²â‚š) = GammaKL(Î±, Î², Î±â‚š, Î²â‚š)
# """
#     GammaKL(Î±, Î², Î±â‚š, Î²â‚š)
#
# KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Ga(Î±,Î²) and p(Ï‰) = Ga(Î±â‚š,Î²â‚š)
# """
# function GammaKL(Î±, Î², Î±â‚š, Î²â‚š)
#     return sum(
#         (Î± - Î±â‚š) .* digamma(Î±) .- log.(gamma.(Î±)) .+ log.(gamma.(Î±â‚š)) .+
#         Î±â‚š .* (log.(Î²) .- log.(Î²â‚š)) .+ Î± .* (Î²â‚š .- Î²) ./ Î²,
#     )
# end
#
"""
    PoissonKL(Î», Î»â‚€)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Po(Ï‰|Î») and p(Ï‰) = Po(Ï‰|Î»â‚€)
"""
function PoissonKL(Î»::AbstractVector{T}, Î»â‚€::Real) where {T}
    return Î»â‚€ * length(Î») - (one(T) + log(Î»â‚€)) * sum(Î») + sum(xlogx, Î»)
end

"""
    PoissonKL(Î», Î»â‚€, Ïˆ)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Po(Ï‰|Î») and p(Ï‰) = Po(Ï‰|Î»â‚€) with Ïˆ = E[log(Î»â‚€)]
"""
function PoissonKL(
    Î»::AbstractVector{<:Real}, Î»â‚€::AbstractVector{<:Real}, Ïˆ::AbstractVector{<:Real}
)
    # sum(Î»â‚€) - sum(Î») + sum(xlogx, Î») - dot(Î», Ïˆ)
    # sum(Î»â‚€) - sum(Î») + mapreduce(xlogx, +, Î») - dot(Î», Ïˆ)
    return sum(Î»â‚€) - sum(Î») + sum(xlogx.(Î»)) - dot(Î», Ïˆ)
end

"""
    PolyaGammaKL(b, c, Î¸)
KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = PG(b,c) and p(Ï‰) = PG(b,0). Î¸ = ð‘¬[Ï‰]
"""
function PolyaGammaKL(b, c, Î¸)
    return dot(b, logcosh.(c / 2)) - dot(abs2.(c), Î¸) / 2
end

# """
#     GIGEntropy(a, b, p)
#
# Entropy of GIG variables with parameters a,b and p and omitting the derivative d/dpK_p cf <https://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution#Entropy>
# """
# function GIGEntropy(a, b, p)
#     sqrt_ab = sqrt.(a .* b)
#     return (sum(log, a) - sum(log, b)) / 2 +
#            mapreduce((p, s) -> log(2 * besselk(p, s)), +, p, sqrt_ab) +
#            sum(
#                sqrt_ab ./ besselk.(p, sqrt_ab) .*
#                (besselk.(p + 1, sqrt_ab) + besselk.(p - 1, sqrt_ab)),
#            ) / 2
# end
